{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fdd0bcb",
   "metadata": {},
   "source": [
    "# [STARTER] Udaplay Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9325b035",
   "metadata": {},
   "source": [
    "## Part 02 - Agent\n",
    "\n",
    "In this part of the project, you'll use your VectorDB to be part of your Agent as a tool.\n",
    "\n",
    "You're building UdaPlay, an AI Research Agent for the video game industry. The agent will:\n",
    "1. Answer questions using internal knowledge (RAG)\n",
    "2. Search the web when needed\n",
    "3. Maintain conversation state\n",
    "4. Return structured outputs\n",
    "5. Store useful information for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b42de90",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a963d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needed for Udacity workspace\n",
    "\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Check if 'pysqlite3' is available before importing\n",
    "if importlib.util.find_spec(\"pysqlite3\") is not None:\n",
    "    import pysqlite3\n",
    "    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd10c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import the necessary libs\n",
    "# For example: \n",
    "import os\n",
    "\n",
    "from lib.agents import Agent\n",
    "from lib.llm import LLM\n",
    "from lib.messages import UserMessage, SystemMessage, ToolMessage, AIMessage\n",
    "from lib.state_machine import StateMachine, Step, EntryPoint, Termination, Run\n",
    "from lib.tooling import ToolCall,tool\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict, Any, Optional, TypedDict\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import json\n",
    "from tavily import TavilyClient\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87e465d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de4729",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab2dac",
   "metadata": {},
   "source": [
    "Build at least 3 tools:\n",
    "- retrieve_game: To search the vector DB\n",
    "- evaluate_retrieval: To assess the retrieval performance\n",
    "- game_web_search: If no good, search the web\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f14cd",
   "metadata": {},
   "source": [
    "#### Retrieve Game Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b25c36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create retrieve_game tool\n",
    "# It should use chroma client and collection you created\n",
    "# chroma_client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "# collection = chroma_client.get_collection(\"udaplay\")\n",
    "# Tool Docstring:\n",
    "#    Semantic search: Finds most results in the vector DB\n",
    "#    args:\n",
    "#    - query: a question about game industry. \n",
    "#\n",
    "#    You'll receive results as list. Each element contains:\n",
    "#    - Platform: like Game Boy, Playstation 5, Xbox 360...)\n",
    "#    - Name: Name of the Game\n",
    "#    - YearOfRelease: Year when that game was released for that platform\n",
    "#    - Description: Additional details about the game\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "collection = chroma_client.get_collection(\"udaplay\")\n",
    "\n",
    "@tool\n",
    "def retrieve_game(query: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Semantic search: Finds most results in the vector DB.\n",
    "\n",
    "    Args:\n",
    "        query: a question about game industry. \n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries. Each element contains:\n",
    "        - Platform: like Game Boy, Playstation 5, Xbox 360...)\n",
    "        - Name: Name of the Game\n",
    "        - YearOfRelease: Year when that game was released for that platform\n",
    "        - Description: Additional details about the game\n",
    "    \"\"\"\n",
    "    \n",
    "    # Query the collection\n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=5, # Retrieve top 5 similar documents\n",
    "        include=['metadatas', 'documents']\n",
    "    )\n",
    "    \n",
    "    formatted_results = []\n",
    "    \n",
    "    # Parse the results safely\n",
    "    if results and results.get('metadatas') and results.get('documents'):\n",
    "        # The query returns a list of lists (batch processing), we take the first index [0]\n",
    "        for metadata, document in zip(results['metadatas'][0], results['documents'][0]):\n",
    "            formatted_results.append({\n",
    "                \"Platform\": metadata.get(\"Platform\", \"Unknown\"),\n",
    "                \"Name\": metadata.get(\"Name\", \"Unknown\"),\n",
    "                \"YearOfRelease\": metadata.get(\"YearOfRelease\", \"Unknown\"),\n",
    "                \"Description\": document \n",
    "            })\n",
    "            \n",
    "    return formatted_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910dc945",
   "metadata": {},
   "source": [
    "#### Evaluate Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9d014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create evaluate_retrieval tool\n",
    "# You might use an LLM as judge in this tool to evaluate the performance\n",
    "# You need to prompt that LLM with something like:\n",
    "# \"Your task is to evaluate if the documents are enough to respond the query. \"\n",
    "# \"Give a detailed explanation, so it's possible to take an action to accept it or not.\"\n",
    "# Use EvaluationReport to parse the result\n",
    "# Tool Docstring:\n",
    "#    Based on the user's question and on the list of retrieved documents, \n",
    "#    it will analyze the usability of the documents to respond to that question. \n",
    "#    args: \n",
    "#    - question: original question from user\n",
    "#    - retrieved_docs: retrieved documents most similar to the user query in the Vector Database\n",
    "#    The result includes:\n",
    "#    - useful: whether the documents are useful to answer the question\n",
    "#    - description: description about the evaluation result\n",
    "\n",
    "class EvaluationReport(BaseModel):\n",
    "    useful: bool = Field(description=\"whether the documents are useful to answer the question\")\n",
    "    description: str = Field(description=\"description about the evaluation result\")\n",
    "\n",
    "@tool\n",
    "def evaluate_retrieval(question: str, retrieved_docs:Optional[List[Dict[str, Any]]] = None) -> EvaluationReport:\n",
    "    \"\"\"\n",
    "    Based on the user's question and on the list of retrieved documents, \n",
    "    it will analyze the usability of the documents to respond to that question. \n",
    "    \n",
    "    Args: \n",
    "    - question: original question from user\n",
    "    - retrieved_docs: retrieved documents most similar to the user query in the Vector Database\n",
    "    \n",
    "    Returns:\n",
    "    - EvaluationReport: Includes boolean 'useful' and a 'description'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the LLM for evaluation\n",
    "    # We instantiate a fresh LLM here to act as the independent 'Judge'\n",
    "    eval_llm = LLM(model=\"gpt-4o\")\n",
    "\n",
    "    # Format the docs into a string for the prompt\n",
    "    docs_content = json.dumps(retrieved_docs, indent=2)\n",
    "\n",
    "    system_prompt = \"\"\"Your task is to evaluate if the documents are enough to respond the query.\n",
    "    Give a detailed explanation, so it's possible to take an action to accept it or not.\"\"\"\n",
    "\n",
    "    user_message = f\"\"\"\n",
    "    User Question: {question}\n",
    "\n",
    "    Retrieved Documents:\n",
    "    {docs_content}\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate the evaluation using the LLM and parse it into the Report format\n",
    "    # We assume the custom LLM class supports an 'output_schema' or similar argument for structured outputs\n",
    "    evaluation = eval_llm.invoke(\n",
    "        system=system_prompt,\n",
    "        input=user_message,\n",
    "        output_schema=EvaluationReport\n",
    "    )\n",
    "    \n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7935a26",
   "metadata": {},
   "source": [
    "#### Game Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ad698aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create game_web_search tool\n",
    "# Please use Tavily client to search the web\n",
    "# Tool Docstring:\n",
    "#    Semantic search: Finds most results in the vector DB\n",
    "#    args:\n",
    "#    - question: a question about game industry. \n",
    "\n",
    "tavily_client = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
    "\n",
    "@tool\n",
    "def game_web_search(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Search the web for current or external information about the game industry.\n",
    "    Use this when the internal database lacks information or for recent news.\n",
    "\n",
    "    Args:\n",
    "        question: a specific question about the game industry. \n",
    "        \n",
    "    Returns:\n",
    "        A summarized string of relevant web search results.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Perform the search\n",
    "    response = tavily_client.search(\n",
    "        query=question,\n",
    "        search_depth=\"advanced\", \n",
    "        include_images=False,\n",
    "        max_results=5,\n",
    "        include_raw_content=False,\n",
    "        include_answer=True # Tries to get a direct answer generated by Tavily\n",
    "    )\n",
    "    \n",
    "    # Format the output\n",
    "    search_results = \"\"\n",
    "    \n",
    "    # Check for a direct answer first\n",
    "    answer = response.get(\"answer\")\n",
    "    if answer:\n",
    "        search_results += f\"Web Search Answer: {answer}\\n\\n\"\n",
    "    else:\n",
    "        search_results += \"Web Search Results:\\n\"\n",
    "        \n",
    "    # Append specific snippets for context\n",
    "    for result in response.get(\"results\", []):\n",
    "        search_results += f\"- Title: {result.get('title', 'No Title')}\\n\"\n",
    "        search_results += f\"  Snippet: {result.get('content', 'No Content')}\\n\"\n",
    "        search_results += f\"  Source: {result.get('url', 'No URL')}\\n\"\n",
    "        search_results += \"---\\n\"\n",
    "        \n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0f86cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_INSTRUCTIONS = \"\"\"\n",
    "You are UdaPlay, an AI Research Agent specializing in the video game industry. \n",
    "Your goal is to answer user questions accurately using the available tools.\n",
    "\n",
    "**Your workflow must be:**\n",
    "1. **Initial Check:** For any question about games, history, or platforms, first use the `retrieve_game` tool to check internal knowledge.\n",
    "2. **Evaluation:** Use the `evaluate_retrieval` tool to check if the retrieved documents are sufficient to answer the question.\n",
    "3. **Action:**\n",
    "    - If the documents are marked as `useful: true`, synthesize the final answer ONLY from those documents.\n",
    "    - If the documents are marked as `useful: false` or if the question is about recent news or external topics not found in the DB, proceed to use the `game_web_search` tool.\n",
    "4. **Final Answer:** Always provide a clear, concise, and direct answer to the user's question based on the most reliable source (VectorDB or Web Search).\n",
    "5. **Memory:** Maintain context from previous turns to answer follow-up questions effectively.\n",
    "\"\"\"\n",
    "\n",
    "udaplay_agent = Agent(\n",
    "    model_name=\"gpt-4o\",\n",
    "    instructions=AGENT_INSTRUCTIONS,\n",
    "    tools=[retrieve_game, evaluate_retrieval, game_web_search],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df844b3b",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c56281",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Agent.__init__() got an unexpected keyword argument 'llm'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     14\u001b[39m AGENT_INSTRUCTIONS = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33mYou are UdaPlay, an AI Research Agent specializing in the video game industry. \u001b[39m\n\u001b[32m     16\u001b[39m \u001b[33mYour goal is to answer user questions accurately using the available tools.\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m \u001b[33m5. **Memory:** Maintain context from previous turns to answer follow-up questions effectively.\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Equip the agent with the necessary model and tools\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m udaplay_agent = \u001b[43mAgent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Use a powerful model for complex reasoning and tool use\u001b[39;49;00m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mAGENT_INSTRUCTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mretrieve_game\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluate_retrieval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgame_web_search\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: Agent.__init__() got an unexpected keyword argument 'llm'"
     ]
    }
   ],
   "source": [
    "# TODO: Create your Agent abstraction using StateMachine\n",
    "# Equip with an appropriate model\n",
    "# Craft a good set of instructions \n",
    "# Plug all Tools you developed\n",
    "\n",
    "# TODO: Create your Agent abstraction using StateMachine\n",
    "\n",
    "\n",
    "# Define the Agent's behavior\n",
    "AGENT_INSTRUCTIONS = \"\"\"\n",
    "You are UdaPlay, an AI Research Agent specializing in the video game industry. \n",
    "Your goal is to answer user questions accurately using the available tools.\n",
    "\n",
    "**Your workflow must be:**\n",
    "1. **Initial Check:** For any question about games, history, or platforms, first use the `retrieve_game` tool to check internal knowledge.\n",
    "2. **Evaluation:** Use the `evaluate_retrieval` tool to check if the retrieved documents are sufficient to answer the question.\n",
    "3. **Action:**\n",
    "    - If the documents are marked as `useful: true`, synthesize the final answer ONLY from those documents.\n",
    "    - If the documents are marked as `useful: false` or if the question is about recent news or external topics not found in the DB, proceed to use the `game_web_search` tool.\n",
    "4. **Final Answer:** Always provide a clear, concise, and direct answer to the user's question based on the most reliable source (VectorDB or Web Search).\n",
    "5. **Memory:** Maintain context from previous turns to answer follow-up questions effectively.\n",
    "\"\"\"\n",
    "\n",
    "# Equip the agent with the necessary model and tools\n",
    "udaplay_agent = Agent(\n",
    "    llm=LLM(model=\"gpt-4o\"), # Use a powerful model for complex reasoning and tool use\n",
    "    instructions=AGENT_INSTRUCTIONS,\n",
    "    tools=[retrieve_game, evaluate_retrieval, game_web_search],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ec23893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing UdaPlay Agent with 3 queries...\n",
      "\n",
      "--- USER: When Pokémon Gold and Silver was released? ---\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "evaluate_retrieval() missing 1 required positional argument: 'retrieved_docs'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m questions:\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--- USER: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     run_object = \u001b[43mudaplay_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m     final_state = run_object.get_final_state()\n\u001b[32m     20\u001b[39m     final_response = final_state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m].content\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/AAIND_UdaPlay/project/starter/lib/agents.py:177\u001b[39m, in \u001b[36mAgent.invoke\u001b[39m\u001b[34m(self, query, session_id)\u001b[39m\n\u001b[32m    167\u001b[39m         previous_messages = last_state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    169\u001b[39m initial_state: AgentState = {\n\u001b[32m    170\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33muser_query\u001b[39m\u001b[33m\"\u001b[39m: query,\n\u001b[32m    171\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minstructions\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.instructions,\n\u001b[32m   (...)\u001b[39m\u001b[32m    174\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msession_id\u001b[39m\u001b[33m\"\u001b[39m: session_id,\n\u001b[32m    175\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m run_object = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mworkflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[38;5;66;03m# Store the complete run object in memory\u001b[39;00m\n\u001b[32m    180\u001b[39m \u001b[38;5;28mself\u001b[39m.memory.add(run_object, session_id)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/AAIND_UdaPlay/project/starter/lib/state_machine.py:231\u001b[39m, in \u001b[36mStateMachine.run\u001b[39m\u001b[34m(self, state, resource)\u001b[39m\n\u001b[32m    228\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    230\u001b[39m \u001b[38;5;66;03m# Replace state entirely\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m state = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstate_schema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(step, EntryPoint):\n\u001b[32m    234\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[StateMachine] Starting: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_step_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/AAIND_UdaPlay/project/starter/lib/state_machine.py:40\u001b[39m, in \u001b[36mStep.run\u001b[39m\u001b[34m(self, state, state_schema, resource)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, state: StateSchema, state_schema: Type[StateSchema], resource: Resource=\u001b[38;5;28;01mNone\u001b[39;00m) -> StateSchema:\n\u001b[32m     38\u001b[39m     \u001b[38;5;66;03m# Call logic function with appropriate number of arguments\u001b[39;00m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.logic_params_count == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlogic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.logic_params_count == \u001b[32m2\u001b[39m:\n\u001b[32m     42\u001b[39m         result = \u001b[38;5;28mself\u001b[39m.logic(state, resource)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/AAIND_UdaPlay/project/starter/lib/agents.py:97\u001b[39m, in \u001b[36mAgent._tool_step\u001b[39m\u001b[34m(self, state)\u001b[39m\n\u001b[32m     95\u001b[39m tool = \u001b[38;5;28mnext\u001b[39m((t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tools \u001b[38;5;28;01mif\u001b[39;00m t.name == function_name), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tool:\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     result = \u001b[38;5;28mstr\u001b[39m(\u001b[43mtool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunction_args\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     98\u001b[39m     tool_message = ToolMessage(\n\u001b[32m     99\u001b[39m         content=json.dumps(result),\n\u001b[32m    100\u001b[39m         tool_call_id=tool_call_id,\n\u001b[32m    101\u001b[39m         name=function_name,\n\u001b[32m    102\u001b[39m     )\n\u001b[32m    103\u001b[39m     tool_messages.append(tool_message)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/AAIND_UdaPlay/project/starter/lib/tooling.py:106\u001b[39m, in \u001b[36mTool.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: evaluate_retrieval() missing 1 required positional argument: 'retrieved_docs'"
     ]
    }
   ],
   "source": [
    "# TODO: Invoke your agent\n",
    "# - When Pokémon Gold and Silver was released?\n",
    "# - Which one was the first 3D platformer Mario game?\n",
    "# - Was Mortal Kombat X realeased for Playstation 5?\n",
    "\n",
    "questions = [\n",
    "    \"When Pokémon Gold and Silver was released?\",          \n",
    "    \"Which one was the first 3D platformer Mario game?\", \n",
    "    \"Was Mortal Kombat X released for Playstation 5?\"\n",
    "]\n",
    "\n",
    "print(f\"Testing UdaPlay Agent with {len(questions)} queries...\\n\")\n",
    "\n",
    "for q in questions:\n",
    "    print(f\"--- USER: {q} ---\")\n",
    "    \n",
    "    run_object = udaplay_agent.invoke(q)\n",
    "    \n",
    "    final_state = run_object.get_final_state()\n",
    "    final_response = final_state[\"messages\"][-1].content\n",
    "    \n",
    "    print(f\"AGENT: {final_response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a55081",
   "metadata": {},
   "source": [
    "### (Optional) Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb83fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update your agent with long-term memory\n",
    "# TODO: Convert the agent to be a state machine, with the tools being pre-defined nodes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
