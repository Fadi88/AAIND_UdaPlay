{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fdd0bcb",
   "metadata": {},
   "source": [
    "# [STARTER] Udaplay Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9325b035",
   "metadata": {},
   "source": [
    "## Part 02 - Agent\n",
    "\n",
    "In this part of the project, you'll use your VectorDB to be part of your Agent as a tool.\n",
    "\n",
    "You're building UdaPlay, an AI Research Agent for the video game industry. The agent will:\n",
    "1. Answer questions using internal knowledge (RAG)\n",
    "2. Search the web when needed\n",
    "3. Maintain conversation state\n",
    "4. Return structured outputs\n",
    "5. Store useful information for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b42de90",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a963d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needed for Udacity workspace\n",
    "\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Check if 'pysqlite3' is available before importing\n",
    "if importlib.util.find_spec(\"pysqlite3\") is not None:\n",
    "    import pysqlite3\n",
    "    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd10c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import the necessary libs\n",
    "# For example: \n",
    "import os\n",
    "\n",
    "from lib.agents import Agent\n",
    "from lib.llm import LLM\n",
    "from lib.messages import UserMessage, SystemMessage, ToolMessage, AIMessage\n",
    "from lib.state_machine import StateMachine, Step, EntryPoint, Termination, Run\n",
    "from lib.tooling import ToolCall,tool\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict, Any, Optional, TypedDict\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import json\n",
    "from tavily import TavilyClient\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87e465d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de4729",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab2dac",
   "metadata": {},
   "source": [
    "Build at least 3 tools:\n",
    "- retrieve_game: To search the vector DB\n",
    "- evaluate_retrieval: To assess the retrieval performance\n",
    "- game_web_search: If no good, search the web\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f14cd",
   "metadata": {},
   "source": [
    "#### Retrieve Game Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b25c36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create retrieve_game tool\n",
    "# It should use chroma client and collection you created\n",
    "# chroma_client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "# collection = chroma_client.get_collection(\"udaplay\")\n",
    "# Tool Docstring:\n",
    "#    Semantic search: Finds most results in the vector DB\n",
    "#    args:\n",
    "#    - query: a question about game industry. \n",
    "#\n",
    "#    You'll receive results as list. Each element contains:\n",
    "#    - Platform: like Game Boy, Playstation 5, Xbox 360...)\n",
    "#    - Name: Name of the Game\n",
    "#    - YearOfRelease: Year when that game was released for that platform\n",
    "#    - Description: Additional details about the game\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "collection = chroma_client.get_collection(\"udaplay\")\n",
    "\n",
    "@tool\n",
    "def retrieve_game(query: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Semantic search: Finds most results in the vector DB.\n",
    "\n",
    "    Args:\n",
    "        query: a question about game industry. \n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries. Each element contains:\n",
    "        - Platform: like Game Boy, Playstation 5, Xbox 360...)\n",
    "        - Name: Name of the Game\n",
    "        - YearOfRelease: Year when that game was released for that platform\n",
    "        - Description: Additional details about the game\n",
    "    \"\"\"\n",
    "    \n",
    "    # Query the collection\n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=5, # Retrieve top 5 similar documents\n",
    "        include=['metadatas', 'documents']\n",
    "    )\n",
    "    \n",
    "    formatted_results = []\n",
    "    \n",
    "    # Parse the results safely\n",
    "    if results and results.get('metadatas') and results.get('documents'):\n",
    "        # The query returns a list of lists (batch processing), we take the first index [0]\n",
    "        for metadata, document in zip(results['metadatas'][0], results['documents'][0]):\n",
    "            formatted_results.append({\n",
    "                \"Platform\": metadata.get(\"Platform\", \"Unknown\"),\n",
    "                \"Name\": metadata.get(\"Name\", \"Unknown\"),\n",
    "                \"YearOfRelease\": metadata.get(\"YearOfRelease\", \"Unknown\"),\n",
    "                \"Description\": document \n",
    "            })\n",
    "            \n",
    "    return formatted_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910dc945",
   "metadata": {},
   "source": [
    "#### Evaluate Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9d014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create evaluate_retrieval tool\n",
    "# You might use an LLM as judge in this tool to evaluate the performance\n",
    "# You need to prompt that LLM with something like:\n",
    "# \"Your task is to evaluate if the documents are enough to respond the query. \"\n",
    "# \"Give a detailed explanation, so it's possible to take an action to accept it or not.\"\n",
    "# Use EvaluationReport to parse the result\n",
    "# Tool Docstring:\n",
    "#    Based on the user's question and on the list of retrieved documents, \n",
    "#    it will analyze the usability of the documents to respond to that question. \n",
    "#    args: \n",
    "#    - question: original question from user\n",
    "#    - retrieved_docs: retrieved documents most similar to the user query in the Vector Database\n",
    "#    The result includes:\n",
    "#    - useful: whether the documents are useful to answer the question\n",
    "#    - description: description about the evaluation result\n",
    "\n",
    "class EvaluationReport(BaseModel):\n",
    "    useful: bool = Field(description=\"whether the documents are useful to answer the question\")\n",
    "    description: str = Field(description=\"description about the evaluation result\")\n",
    "\n",
    "@tool\n",
    "def evaluate_retrieval(question: str, retrieved_docs: Optional[List[Dict[str, Any]]] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Analyzes if retrieved documents answer the question.\n",
    "    \"\"\"\n",
    "    # 1. Safety check for missing argument\n",
    "    if retrieved_docs is None:\n",
    "        return json.dumps({\n",
    "            \"useful\": False, \n",
    "            \"description\": \"Error: 'retrieved_docs' was missing. Please pass the output of 'retrieve_game'.\"\n",
    "        })\n",
    "\n",
    "    # 2. Initialize LLM\n",
    "    eval_llm = LLM(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    # 3. Create Message List (System + User)\n",
    "    # We wrap the system prompt in a SystemMessage object\n",
    "    docs_content = json.dumps(retrieved_docs, indent=2)\n",
    "    messages = [\n",
    "        SystemMessage(content=\"Your task is to evaluate if the documents are enough to respond the query. Return a JSON with 'useful': true/false and a description.\"),\n",
    "        UserMessage(content=f\"User Question: {question}\\n\\nRetrieved Documents:\\n{docs_content}\")\n",
    "    ]\n",
    "\n",
    "    # 4. Invoke using valid arguments: 'input' and 'response_format'\n",
    "    try:\n",
    "        response = eval_llm.invoke(\n",
    "            input=messages, \n",
    "            response_format=EvaluationReport\n",
    "        )\n",
    "        \n",
    "        # Parse valid JSON from the response content\n",
    "        report = EvaluationReport.model_validate_json(response.content)\n",
    "        return report.model_dump()\n",
    "        \n",
    "    except Exception as e:\n",
    "        return json.dumps({\n",
    "            \"useful\": False, \n",
    "            \"description\": f\"Evaluation failed: {str(e)}\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7935a26",
   "metadata": {},
   "source": [
    "#### Game Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ad698aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create game_web_search tool\n",
    "# Please use Tavily client to search the web\n",
    "# Tool Docstring:\n",
    "#    Semantic search: Finds most results in the vector DB\n",
    "#    args:\n",
    "#    - question: a question about game industry. \n",
    "\n",
    "tavily_client = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
    "\n",
    "@tool\n",
    "def game_web_search(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Search the web for current or external information about the game industry.\n",
    "    Use this when the internal database lacks information or for recent news.\n",
    "\n",
    "    Args:\n",
    "        question: a specific question about the game industry. \n",
    "        \n",
    "    Returns:\n",
    "        A summarized string of relevant web search results.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Perform the search\n",
    "    response = tavily_client.search(\n",
    "        query=question,\n",
    "        search_depth=\"advanced\", \n",
    "        include_images=False,\n",
    "        max_results=5,\n",
    "        include_raw_content=False,\n",
    "        include_answer=True # Tries to get a direct answer generated by Tavily\n",
    "    )\n",
    "    \n",
    "    # Format the output\n",
    "    search_results = \"\"\n",
    "    \n",
    "    # Check for a direct answer first\n",
    "    answer = response.get(\"answer\")\n",
    "    if answer:\n",
    "        search_results += f\"Web Search Answer: {answer}\\n\\n\"\n",
    "    else:\n",
    "        search_results += \"Web Search Results:\\n\"\n",
    "        \n",
    "    # Append specific snippets for context\n",
    "    for result in response.get(\"results\", []):\n",
    "        search_results += f\"- Title: {result.get('title', 'No Title')}\\n\"\n",
    "        search_results += f\"  Snippet: {result.get('content', 'No Content')}\\n\"\n",
    "        search_results += f\"  Source: {result.get('url', 'No URL')}\\n\"\n",
    "        search_results += \"---\\n\"\n",
    "        \n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df844b3b",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31c56281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create your Agent abstraction using StateMachine\n",
    "# Equip with an appropriate model\n",
    "# Craft a good set of instructions \n",
    "# Plug all Tools you developed\n",
    "\n",
    "# TODO: Create your Agent abstraction using StateMachine\n",
    "\n",
    "# Define the Agent's behavior\n",
    "AGENT_INSTRUCTIONS = \"\"\"\n",
    "You are UdaPlay, an AI Research Agent specializing in the video game industry. \n",
    "Your goal is to answer user questions accurately using the available tools.\n",
    "\n",
    "**Your workflow must be:**\n",
    "1. **Initial Check:** For any question about games, history, or platforms, first use the `retrieve_game` tool to check internal knowledge.\n",
    "2. **Evaluation:** Use the `evaluate_retrieval` tool to check if the retrieved documents are sufficient to answer the question.\n",
    "3. **Action:**\n",
    "    - If the documents are marked as `useful: true`, synthesize the final answer ONLY from those documents and cite the specific document used.\n",
    "    - If the documents are marked as `useful: false` or if the question is about recent news or external topics not found in the DB, proceed to use the `game_web_search` tool.\n",
    "4. **Final Answer:** Always provide a clear, concise, and direct answer to the user's question based on the most reliable source (VectorDB or Web Search).\n",
    "if the answer is from the internet, make sure to include the url in the response.\n",
    "5. **Memory:** Maintain context from previous turns to answer follow-up questions effectively.\n",
    "\"\"\"\n",
    "\n",
    "# Equip the agent with the necessary model and tools\n",
    "udaplay_agent = Agent(\n",
    "    model_name=\"gpt-4o\", # Use a powerful model for complex reasoning and tool use\n",
    "    instructions=AGENT_INSTRUCTIONS,\n",
    "    tools=[retrieve_game, evaluate_retrieval, game_web_search],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ec23893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing UdaPlay Agent with 4 queries...\n",
      "\n",
      "--- USER: When Pokémon Gold and Silver was released? ---\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "AGENT: Pokémon Gold and Silver were released in Japan on November 21, 1999, and in North America on October 15, 2000. [Source](https://www.pokemon.com/us/pokemon-video-games/pokemon-gold-version-and-pokemon-silver-version)\n",
      "\n",
      "--- USER: Which one was the first 3D platformer Mario game? ---\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "AGENT: The first 3D platformer in the Mario series was \"Super Mario 64,\" released in 1996 for the Nintendo 64. It introduced groundbreaking 3D gameplay mechanics and is widely recognized as a pioneering title in the 3D platformer genre. [Source](https://nintendo.fandom.com/wiki/Super_Mario_64)\n",
      "\n",
      "--- USER: Was Mortal Kombat X released for Playstation 5? ---\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "AGENT: Mortal Kombat X was not released for the PlayStation 5. It was initially released for PlayStation 4, Xbox One, and PC on April 14, 2015. However, it is playable on PlayStation 5 through backward compatibility, although some features available on PS4 may be absent. [Source](https://en.wikipedia.org/wiki/Mortal_Kombat_X)\n",
      "\n",
      "--- USER: What was the release year of that Mario game you just mentioned? ---\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "AGENT: The release year of \"Super Mario 64\" was 1996.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Invoke your agent\n",
    "# - When Pokémon Gold and Silver was released?\n",
    "# - Which one was the first 3D platformer Mario game?\n",
    "# - Was Mortal Kombat X realeased for Playstation 5?\n",
    "\n",
    "questions = [\n",
    "    \"When Pokémon Gold and Silver was released?\",          \n",
    "    \"Which one was the first 3D platformer Mario game?\", \n",
    "    \"Was Mortal Kombat X released for Playstation 5?\",\n",
    "    \"What was the release year of that Mario game you just mentioned?\"\n",
    "]\n",
    "\n",
    "print(f\"Testing UdaPlay Agent with {len(questions)} queries...\\n\")\n",
    "\n",
    "for q in questions:\n",
    "    print(f\"--- USER: {q} ---\")\n",
    "    \n",
    "    run_object = udaplay_agent.invoke(q)\n",
    "    \n",
    "    final_state = run_object.get_final_state()\n",
    "    final_response = final_state[\"messages\"][-1].content\n",
    "    \n",
    "    print(f\"AGENT: {final_response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3486294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "The most famous games from 2010 to 2015 include:\n",
      "\n",
      "1. **Red Dead Redemption** (2010) - Celebrated for its storytelling and open-world gameplay.\n",
      "2. **The Last of Us** (2013) - Known for its emotional narrative and character development.\n",
      "3. **Grand Theft Auto V** (2013) - Famous for its expansive open world and engaging missions.\n",
      "4. **The Witcher 3: Wild Hunt** (2015) - Acclaimed for its rich story and open-world exploration.\n",
      "5. **Dark Souls** (2011) - Renowned for its challenging gameplay and intricate world design.\n",
      "6. **Elder Scrolls V: Skyrim** (2011) - Popular for its immersive world and modding community.\n",
      "7. **Portal 2** (2011) - Praised for its clever puzzles and humorous writing.\n",
      "8. **Mass Effect 2** (2010) - Notable for its engaging story and character interactions.\n",
      "9. **Minecraft** (2011) - Known for its creative sandbox gameplay.\n",
      "10. **Bloodborne** (2015) - Famous for its atmospheric world and challenging combat.\n",
      "\n",
      "These games have been recognized for their impact on the gaming industry during that period. For more detailed lists, you can check sources like [VG247](https://www.vg247.com/best-video-games-of-the-decade-the-top-50-games-from-2010-2020-ranked) and [YouTube](https://www.youtube.com/watch?v=Blcqg_vz7po).\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "Here are the platforms for each of the mentioned games:\n",
      "\n",
      "1. **Red Dead Redemption** (2010)\n",
      "   - Platforms: PlayStation 3, Xbox 360\n",
      "\n",
      "2. **The Last of Us** (2013)\n",
      "   - Platforms: PlayStation 3, PlayStation 4 (Remastered version)\n",
      "\n",
      "3. **Grand Theft Auto V** (2013)\n",
      "   - Platforms: PlayStation 3, Xbox 360, PlayStation 4, Xbox One, PC\n",
      "\n",
      "4. **The Witcher 3: Wild Hunt** (2015)\n",
      "   - Platforms: PlayStation 4, Xbox One, PC, Nintendo Switch\n",
      "\n",
      "5. **Dark Souls** (2011)\n",
      "   - Platforms: PlayStation 3, Xbox 360, PC\n",
      "\n",
      "6. **Elder Scrolls V: Skyrim** (2011)\n",
      "   - Platforms: PlayStation 3, Xbox 360, PC, PlayStation 4, Xbox One, Nintendo Switch\n",
      "\n",
      "7. **Portal 2** (2011)\n",
      "   - Platforms: PlayStation 3, Xbox 360, PC, Mac\n",
      "\n",
      "8. **Mass Effect 2** (2010)\n",
      "   - Platforms: PlayStation 3, Xbox 360, PC\n",
      "\n",
      "9. **Minecraft** (2011)\n",
      "   - Platforms: PC, Mac, Linux, PlayStation 3, PlayStation 4, PlayStation Vita, Xbox 360, Xbox One, Wii U, Nintendo Switch, iOS, Android\n",
      "\n",
      "10. **Bloodborne** (2015)\n",
      "   - Platforms: PlayStation 4\n",
      "\n",
      "These platforms reflect the original and any subsequent releases for each game.\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "Choosing the best game from this list is subjective and depends on personal preferences, but many would argue that **The Witcher 3: Wild Hunt** is often considered one of the best due to its:\n",
      "\n",
      "- Deep and engaging story\n",
      "- Rich open-world environment\n",
      "- Strong character development\n",
      "- High-quality graphics and music\n",
      "\n",
      "It has received numerous Game of the Year awards and remains highly influential in the RPG genre.\n"
     ]
    }
   ],
   "source": [
    "# check if memory is maintained between two runs with the same sesion id\n",
    "SESSION_ID = \"my_udaplay_session_001\"\n",
    "\n",
    "q1 = \"What are the most famous games from 2010-2015?\"\n",
    "q2 = \"On which platfroms did those games run?\"\n",
    "q3 = \"if you pick the best game out of those and only one, which one will you pick?\"\n",
    "\n",
    "print(udaplay_agent.invoke(q1, session_id=SESSION_ID).get_final_state()[\"messages\"][-1].content)\n",
    "print(udaplay_agent.invoke(q2, session_id=SESSION_ID).get_final_state()[\"messages\"][-1].content)\n",
    "print(udaplay_agent.invoke(q3, session_id=SESSION_ID).get_final_state()[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a55081",
   "metadata": {},
   "source": [
    "### (Optional) Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb83fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update your agent with long-term memory\n",
    "# TODO: Convert the agent to be a state machine, with the tools being pre-defined nodes\n",
    "# TODO: Visualization: Create a dashboard or visualization of the agent’s retrieval process or knowledge base.\n",
    "# TODO: Structured Output: Return answers in both natural language and structured JSON for easy integration.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
