{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fdd0bcb",
   "metadata": {},
   "source": [
    "# [STARTER] Udaplay Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9325b035",
   "metadata": {},
   "source": [
    "## Part 02 - Agent\n",
    "\n",
    "In this part of the project, you'll use your VectorDB to be part of your Agent as a tool.\n",
    "\n",
    "You're building UdaPlay, an AI Research Agent for the video game industry. The agent will:\n",
    "1. Answer questions using internal knowledge (RAG)\n",
    "2. Search the web when needed\n",
    "3. Maintain conversation state\n",
    "4. Return structured outputs\n",
    "5. Store useful information for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b42de90",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a963d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needed for Udacity workspace\n",
    "\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Check if 'pysqlite3' is available before importing\n",
    "if importlib.util.find_spec(\"pysqlite3\") is not None:\n",
    "    import pysqlite3\n",
    "    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd10c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import the necessary libs\n",
    "# For example: \n",
    "import os\n",
    "\n",
    "from lib.agents import Agent\n",
    "from lib.llm import LLM\n",
    "from lib.messages import UserMessage, SystemMessage, ToolMessage, AIMessage\n",
    "from lib.state_machine import StateMachine, Step, EntryPoint, Termination, Run\n",
    "from lib.tooling import ToolCall,tool\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict, Any, Optional, TypedDict\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import json\n",
    "from tavily import TavilyClient\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87e465d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de4729",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab2dac",
   "metadata": {},
   "source": [
    "Build at least 3 tools:\n",
    "- retrieve_game: To search the vector DB\n",
    "- evaluate_retrieval: To assess the retrieval performance\n",
    "- game_web_search: If no good, search the web\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f14cd",
   "metadata": {},
   "source": [
    "#### Retrieve Game Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b25c36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create retrieve_game tool\n",
    "# It should use chroma client and collection you created\n",
    "# chroma_client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "# collection = chroma_client.get_collection(\"udaplay\")\n",
    "# Tool Docstring:\n",
    "#    Semantic search: Finds most results in the vector DB\n",
    "#    args:\n",
    "#    - query: a question about game industry. \n",
    "#\n",
    "#    You'll receive results as list. Each element contains:\n",
    "#    - Platform: like Game Boy, Playstation 5, Xbox 360...)\n",
    "#    - Name: Name of the Game\n",
    "#    - YearOfRelease: Year when that game was released for that platform\n",
    "#    - Description: Additional details about the game\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "collection = chroma_client.get_collection(\"udaplay\")\n",
    "\n",
    "@tool\n",
    "def retrieve_game(query: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Semantic search: Finds most results in the vector DB.\n",
    "\n",
    "    Args:\n",
    "        query: a question about game industry. \n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries. Each element contains:\n",
    "        - Platform: like Game Boy, Playstation 5, Xbox 360...)\n",
    "        - Name: Name of the Game\n",
    "        - YearOfRelease: Year when that game was released for that platform\n",
    "        - Description: Additional details about the game\n",
    "    \"\"\"\n",
    "    \n",
    "    # Query the collection\n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=5, # Retrieve top 5 similar documents\n",
    "        include=['metadatas', 'documents']\n",
    "    )\n",
    "    \n",
    "    formatted_results = []\n",
    "    \n",
    "    # Parse the results safely\n",
    "    if results and results.get('metadatas') and results.get('documents'):\n",
    "        # The query returns a list of lists (batch processing), we take the first index [0]\n",
    "        for metadata, document in zip(results['metadatas'][0], results['documents'][0]):\n",
    "            formatted_results.append({\n",
    "                \"Platform\": metadata.get(\"Platform\", \"Unknown\"),\n",
    "                \"Name\": metadata.get(\"Name\", \"Unknown\"),\n",
    "                \"YearOfRelease\": metadata.get(\"YearOfRelease\", \"Unknown\"),\n",
    "                \"Description\": document \n",
    "            })\n",
    "            \n",
    "    return formatted_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910dc945",
   "metadata": {},
   "source": [
    "#### Evaluate Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d9d014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create evaluate_retrieval tool\n",
    "# You might use an LLM as judge in this tool to evaluate the performance\n",
    "# You need to prompt that LLM with something like:\n",
    "# \"Your task is to evaluate if the documents are enough to respond the query. \"\n",
    "# \"Give a detailed explanation, so it's possible to take an action to accept it or not.\"\n",
    "# Use EvaluationReport to parse the result\n",
    "# Tool Docstring:\n",
    "#    Based on the user's question and on the list of retrieved documents, \n",
    "#    it will analyze the usability of the documents to respond to that question. \n",
    "#    args: \n",
    "#    - question: original question from user\n",
    "#    - retrieved_docs: retrieved documents most similar to the user query in the Vector Database\n",
    "#    The result includes:\n",
    "#    - useful: whether the documents are useful to answer the question\n",
    "#    - description: description about the evaluation result\n",
    "\n",
    "class EvaluationReport(BaseModel):\n",
    "    useful: bool = Field(description=\"whether the documents are useful to answer the question\")\n",
    "    description: str = Field(description=\"description about the evaluation result\")\n",
    "\n",
    "@tool\n",
    "def evaluate_retrieval(question: str, retrieved_docs: Optional[List[Dict[str, Any]]] = None) -> str:\n",
    "    \"\"\"\n",
    "    Analyzes if retrieved documents answer the question.\n",
    "    \"\"\"\n",
    "    # 1. Safety check for missing argument\n",
    "    if retrieved_docs is None:\n",
    "        return json.dumps({\n",
    "            \"useful\": False, \n",
    "            \"description\": \"Error: 'retrieved_docs' was missing. Please pass the output of 'retrieve_game'.\"\n",
    "        })\n",
    "\n",
    "    # 2. Initialize LLM\n",
    "    eval_llm = LLM(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    # 3. Create Message List (System + User)\n",
    "    # We wrap the system prompt in a SystemMessage object\n",
    "    docs_content = json.dumps(retrieved_docs, indent=2)\n",
    "    messages = [\n",
    "        SystemMessage(content=\"Your task is to evaluate if the documents are enough to respond the query. Return a JSON with 'useful': true/false and a description.\"),\n",
    "        UserMessage(content=f\"User Question: {question}\\n\\nRetrieved Documents:\\n{docs_content}\")\n",
    "    ]\n",
    "\n",
    "    # 4. Invoke using valid arguments: 'input' and 'response_format'\n",
    "    try:\n",
    "        response = eval_llm.invoke(\n",
    "            input=messages, \n",
    "            response_format=EvaluationReport\n",
    "        )\n",
    "        \n",
    "        # Parse valid JSON from the response content\n",
    "        report = EvaluationReport.model_validate_json(response.content)\n",
    "        return report.model_dump_json()\n",
    "        \n",
    "    except Exception as e:\n",
    "        return json.dumps({\n",
    "            \"useful\": False, \n",
    "            \"description\": f\"Evaluation failed: {str(e)}\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7935a26",
   "metadata": {},
   "source": [
    "#### Game Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ad698aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create game_web_search tool\n",
    "# Please use Tavily client to search the web\n",
    "# Tool Docstring:\n",
    "#    Semantic search: Finds most results in the vector DB\n",
    "#    args:\n",
    "#    - question: a question about game industry. \n",
    "\n",
    "tavily_client = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
    "\n",
    "@tool\n",
    "def game_web_search(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Search the web for current or external information about the game industry.\n",
    "    Use this when the internal database lacks information or for recent news.\n",
    "\n",
    "    Args:\n",
    "        question: a specific question about the game industry. \n",
    "        \n",
    "    Returns:\n",
    "        A summarized string of relevant web search results.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Perform the search\n",
    "    response = tavily_client.search(\n",
    "        query=question,\n",
    "        search_depth=\"advanced\", \n",
    "        include_images=False,\n",
    "        max_results=5,\n",
    "        include_raw_content=False,\n",
    "        include_answer=True # Tries to get a direct answer generated by Tavily\n",
    "    )\n",
    "    \n",
    "    # Format the output\n",
    "    search_results = \"\"\n",
    "    \n",
    "    # Check for a direct answer first\n",
    "    answer = response.get(\"answer\")\n",
    "    if answer:\n",
    "        search_results += f\"Web Search Answer: {answer}\\n\\n\"\n",
    "    else:\n",
    "        search_results += \"Web Search Results:\\n\"\n",
    "        \n",
    "    # Append specific snippets for context\n",
    "    for result in response.get(\"results\", []):\n",
    "        search_results += f\"- Title: {result.get('title', 'No Title')}\\n\"\n",
    "        search_results += f\"  Snippet: {result.get('content', 'No Content')}\\n\"\n",
    "        search_results += f\"  Source: {result.get('url', 'No URL')}\\n\"\n",
    "        search_results += \"---\\n\"\n",
    "        \n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df844b3b",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31c56281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create your Agent abstraction using StateMachine\n",
    "# Equip with an appropriate model\n",
    "# Craft a good set of instructions \n",
    "# Plug all Tools you developed\n",
    "\n",
    "# TODO: Create your Agent abstraction using StateMachine\n",
    "\n",
    "# Define the Agent's behavior\n",
    "AGENT_INSTRUCTIONS = \"\"\"\n",
    "You are UdaPlay, an AI Research Agent specializing in the video game industry. \n",
    "Your goal is to answer user questions accurately using the available tools.\n",
    "\n",
    "**Your workflow must be:**\n",
    "1. **Initial Check:** For any question about games, history, or platforms, first use the `retrieve_game` tool to check internal knowledge.\n",
    "2. **Evaluation:** Use the `evaluate_retrieval` tool to check if the retrieved documents are sufficient to answer the question.\n",
    "3. **Action:**\n",
    "    - If the documents are marked as `useful: true`, synthesize the final answer ONLY from those documents and cite the specific document used.\n",
    "    - If the documents are marked as `useful: false` or if the question is about recent news or external topics not found in the DB, proceed to use the `game_web_search` tool.\n",
    "4. **Final Answer:** Always provide a clear, concise, and direct answer to the user's question based on the most reliable source (VectorDB or Web Search).\n",
    "5. **Memory:** Maintain context from previous turns to answer follow-up questions effectively.\n",
    "\"\"\"\n",
    "\n",
    "# Equip the agent with the necessary model and tools\n",
    "udaplay_agent = Agent(\n",
    "    model_name=\"gpt-4o\", # Use a powerful model for complex reasoning and tool use\n",
    "    instructions=AGENT_INSTRUCTIONS,\n",
    "    tools=[retrieve_game, evaluate_retrieval, game_web_search],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ec23893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing UdaPlay Agent with 4 queries...\n",
      "\n",
      "--- USER: When Pokémon Gold and Silver was released? ---\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "AGENT: Pokémon Gold and Silver were released for the Game Boy Color in 1999.\n",
      "\n",
      "--- USER: Which one was the first 3D platformer Mario game? ---\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "AGENT: The first 3D platformer Mario game was \"Super Mario 64,\" which was released in 1996 for the Nintendo 64. It was a groundbreaking game that set new standards for the platforming genre.\n",
      "\n",
      "--- USER: Was Mortal Kombat X released for Playstation 5? ---\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "AGENT: Mortal Kombat X was not specifically released for PlayStation 5. It was originally released for PlayStation 4, Xbox One, and PC on April 14, 2015. However, it can be played on PlayStation 5 through backward compatibility, though some features available on the PS4 may be absent on the PS5.\n",
      "\n",
      "--- USER: What was the release year of that Mario game you just mentioned? ---\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "AGENT: \"Super Mario 64\" was released in the year 1996 for the Nintendo 64.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Invoke your agent\n",
    "# - When Pokémon Gold and Silver was released?\n",
    "# - Which one was the first 3D platformer Mario game?\n",
    "# - Was Mortal Kombat X realeased for Playstation 5?\n",
    "\n",
    "questions = [\n",
    "    \"When Pokémon Gold and Silver was released?\",          \n",
    "    \"Which one was the first 3D platformer Mario game?\", \n",
    "    \"Was Mortal Kombat X released for Playstation 5?\",\n",
    "    \"What was the release year of that Mario game you just mentioned?\"\n",
    "]\n",
    "\n",
    "print(f\"Testing UdaPlay Agent with {len(questions)} queries...\\n\")\n",
    "\n",
    "for q in questions:\n",
    "    print(f\"--- USER: {q} ---\")\n",
    "    \n",
    "    run_object = udaplay_agent.invoke(q)\n",
    "    \n",
    "    final_state = run_object.get_final_state()\n",
    "    final_response = final_state[\"messages\"][-1].content\n",
    "    \n",
    "    print(f\"AGENT: {final_response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a55081",
   "metadata": {},
   "source": [
    "### (Optional) Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb83fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update your agent with long-term memory\n",
    "# TODO: Convert the agent to be a state machine, with the tools being pre-defined nodes\n",
    "# TODO: Visualization: Create a dashboard or visualization of the agent’s retrieval process or knowledge base.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
