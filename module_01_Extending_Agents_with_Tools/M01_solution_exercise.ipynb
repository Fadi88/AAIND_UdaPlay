{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "541a5c9c",
   "metadata": {},
   "source": [
    "# [SOLUTION] Exercise - Building an AI Agent with Tools\n",
    "\n",
    "In this exercise, you'll build an AI agent that can use tools to enhance its capabilities. You'll learn how to create an agent that can understand when to use tools, process their results, and maintain a coherent conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0918d12a",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Imagine you're building a smart coding assistant that needs to:\n",
    "- Answer programming questions\n",
    "- Execute code snippets\n",
    "- Look up documentation\n",
    "- Perform calculations\n",
    "- Search through codebases\n",
    "\n",
    "Instead of hard-coding when to use each capability, your agent should intelligently decide when and how to use its available tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9c89db",
   "metadata": {},
   "source": [
    "## Setup\n",
    "First, let's import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a220d2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Any\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import os\n",
    "\n",
    "from lib.messages import UserMessage, SystemMessage, ToolMessage\n",
    "from lib.tooling import tool\n",
    "from lib.llm import LLM\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cec412",
   "metadata": {},
   "source": [
    "## Understanding the Components\n",
    "\n",
    "Before we build our agent, let's understand the key components we'll be working with:\n",
    "\n",
    "- `LLM`: The language model wrapper that handles tool execution\n",
    "- `SystemMessage`: Defines the agent's role and behavior\n",
    "- `UserMessage`: Represents user inputs\n",
    "- `ToolMessage`: Contains tool execution results\n",
    "- `tool`: Decorator for creating tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92058e5",
   "metadata": {},
   "source": [
    "## Building the Agent Class\n",
    "\n",
    "Your task is to create an Agent class that can:\n",
    "1. Initialize with a specific role and set of tools\n",
    "2. Process user messages\n",
    "3. Decide when to use tools\n",
    "4. Handle tool responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f95460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \"\"\"An AI Agent that can use tools to help answer questions\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        role: str = \"Personal Assistant\",\n",
    "        instructions: str = \"Help users with any question\",\n",
    "        model: str = \"gpt-4o-mini\",\n",
    "        temperature: float = 0.0,\n",
    "        tools: List[Any] = None\n",
    "    ):\n",
    "        \"\"\"Initialize the agent with its configuration and tools\n",
    "        \n",
    "        Args:\n",
    "            role: The agent's role/persona\n",
    "            instructions: Basic instructions for the agent\n",
    "            model: The LLM model to use\n",
    "            temperature: Creativity parameter (0.0 = more 'deterministic')\n",
    "            tools: List of tools the agent can use\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.role = role\n",
    "        self.instructions = instructions\n",
    "        self.tools = tools\n",
    "\n",
    "        # Load environment variables (e.g. API keys)\n",
    "        load_dotenv()\n",
    "        \n",
    "        # Initialize the LLM with tools if provided\n",
    "        self.llm = LLM(\n",
    "            api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "            tools=tools,\n",
    "        )\n",
    "\n",
    "    def invoke(self, user_message: str) -> str:\n",
    "        \"\"\"Process a user message and return a response\n",
    "        \n",
    "        Args:\n",
    "            user_message: The user's input message\n",
    "            \n",
    "        Returns:\n",
    "            The agent's response after processing tools if needed\n",
    "        \"\"\"\n",
    "        messages = [\n",
    "            SystemMessage(\n",
    "                content=(\n",
    "                    f\"You're an AI Agent and your role is {self.role}. \"  \n",
    "                    f\"Your instructions: {self.instructions}\"\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "        # Add user message to conversation\n",
    "        messages.append(UserMessage(content=user_message))\n",
    "        \n",
    "        # Get AI response and add to conversation\n",
    "        ai_message = self.llm.invoke(messages)\n",
    "        messages.append(ai_message)\n",
    "\n",
    "        # Check if tools were required\n",
    "        while ai_message.tool_calls:\n",
    "            # Process each tool call                    \n",
    "            for call in ai_message.tool_calls:\n",
    "                # Access tool call data correctly\n",
    "                function_name = call.function.name\n",
    "                function_args = json.loads(call.function.arguments)\n",
    "                tool_call_id = call.id\n",
    "                # Find the matching tool\n",
    "                tool = next((t for t in self.tools if t.name == function_name), None)\n",
    "                if tool:\n",
    "                    result = tool(**function_args)\n",
    "                    messages.append(\n",
    "                        ToolMessage(\n",
    "                            content=json.dumps(result), \n",
    "                            tool_call_id=tool_call_id, \n",
    "                            name=function_name, \n",
    "                        )\n",
    "                    )\n",
    "                \n",
    "            # Get final AI response after tool usage and add to conversation\n",
    "            ai_message = self.llm.invoke(messages)\n",
    "            messages.append(ai_message)\n",
    "\n",
    "        for m in messages:\n",
    "            print(m)\n",
    "        return ai_message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda3c9b8",
   "metadata": {},
   "source": [
    "## Testing Your Agent\n",
    "\n",
    "Once you've implemented the Agent class, test it with different scenarios:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cef22d6",
   "metadata": {},
   "source": [
    "1. Basic conversation without tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fdf9fa0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: voc-3732*************************************0466. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m agent = Agent(role=\u001b[33m\"\u001b[39m\u001b[33mCoding Assistant\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m response = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is Python? Be concise\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mAgent.invoke\u001b[39m\u001b[34m(self, user_message)\u001b[39m\n\u001b[32m     54\u001b[39m messages.append(UserMessage(content=user_message))\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Get AI response and add to conversation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m ai_message = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m messages.append(ai_message)\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Check if tools were required\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/AAIND_UdaPlay/module_01_Extending_Agents_with_Tools/lib/llm.py:57\u001b[39m, in \u001b[36mLLM.invoke\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     55\u001b[39m messages = \u001b[38;5;28mself\u001b[39m._convert_input(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m     56\u001b[39m payload = \u001b[38;5;28mself\u001b[39m._build_payload(messages)\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m choice = response.choices[\u001b[32m0\u001b[39m]\n\u001b[32m     59\u001b[39m message = choice.message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/AAIND_UdaPlay/agentic_ai/lib/python3.12/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/AAIND_UdaPlay/agentic_ai/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:1189\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1142\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1143\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1144\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1186\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1187\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1188\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1213\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1214\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1215\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1216\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1217\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1218\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1225\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1228\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1229\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1230\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1231\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1232\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1238\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/AAIND_UdaPlay/agentic_ai/lib/python3.12/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/AAIND_UdaPlay/agentic_ai/lib/python3.12/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: voc-3732*************************************0466. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "agent = Agent(role=\"Coding Assistant\")\n",
    "response = agent.invoke(\"What is Python? Be concise\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661ec4ce",
   "metadata": {},
   "source": [
    "2. Create a calculator tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71c637de",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculate(expression: str) -> float:\n",
    "    \"\"\"Evaluate a mathematical expression\"\"\"\n",
    "    return eval(expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e3204ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent with the calculator tool\n",
    "math_agent = Agent(\n",
    "    role=\"Math Assistant\",\n",
    "    tools=[calculate]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "437c9e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"You're an AI Agent and your role is Math Assistant. Your instructions: Help users with any question\" role='system'\n",
      "content='What is 23 * 45?' role='user'\n",
      "content=None role='assistant' tool_calls=[ChatCompletionMessageToolCall(id='call_klzgArJHewvSYoIzGo8IQdJs', function=Function(arguments='{\"expression\":\"23 * 45\"}', name='calculate'), type='function')]\n",
      "content='1035' role='tool' tool_call_id='call_klzgArJHewvSYoIzGo8IQdJs' name='calculate'\n",
      "content='The result of \\\\( 23 \\\\times 45 \\\\) is 1035.' role='assistant' tool_calls=None\n",
      "The result of \\( 23 \\times 45 \\) is 1035.\n"
     ]
    }
   ],
   "source": [
    "response = math_agent.invoke(\"What is 23 * 45?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e1b6096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"You're an AI Agent and your role is Math Assistant. Your instructions: Help users with any question\" role='system'\n",
      "content='If I multiply 3 by 5, what do I get? Then later add 7' role='user'\n",
      "content=None role='assistant' tool_calls=[ChatCompletionMessageToolCall(id='call_ng19o6ZlDmgnlLdU2m3hyqSs', function=Function(arguments='{\"expression\": \"3 * 5\"}', name='calculate'), type='function'), ChatCompletionMessageToolCall(id='call_EVP76gLh7JUWys9uQqyRYQ3c', function=Function(arguments='{\"expression\": \"3 * 5 + 7\"}', name='calculate'), type='function')]\n",
      "content='15' role='tool' tool_call_id='call_ng19o6ZlDmgnlLdU2m3hyqSs' name='calculate'\n",
      "content='22' role='tool' tool_call_id='call_EVP76gLh7JUWys9uQqyRYQ3c' name='calculate'\n",
      "content='If you multiply 3 by 5, you get 15. If you then add 7 to that result, you get 22.' role='assistant' tool_calls=None\n",
      "If you multiply 3 by 5, you get 15. If you then add 7 to that result, you get 22.\n"
     ]
    }
   ],
   "source": [
    "# Test multiple tool usage\n",
    "response = math_agent.invoke(\"If I multiply 3 by 5, what do I get? Then later add 7\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a3a881",
   "metadata": {},
   "source": [
    "3. Create a data analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfb01df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_games(num_games:int=1, top:bool=True) -> str:\n",
    "    \"\"\"\n",
    "    Returns the top or bottom N games with highest or lowest scores.    \n",
    "    args:\n",
    "        num_games (int): Number of games to return (default is 1)\n",
    "        top (bool): If True, return top games, otherwise return bottom (default is True)\n",
    "    \"\"\"\n",
    "    data = [\n",
    "        {\"Game\": \"The Legend of Zelda: Breath of the Wild\", \"Platform\": \"Switch\", \"Score\": 98},\n",
    "        {\"Game\": \"Super Mario Odyssey\", \"Platform\": \"Switch\", \"Score\": 97},\n",
    "        {\"Game\": \"Metroid Prime\", \"Platform\": \"GameCube\", \"Score\": 97},\n",
    "        {\"Game\": \"Super Smash Bros. Brawl\", \"Platform\": \"Wii\", \"Score\": 93},\n",
    "        {\"Game\": \"Mario Kart 8 Deluxe\", \"Platform\": \"Switch\", \"Score\": 92},\n",
    "        {\"Game\": \"Fire Emblem: Awakening\", \"Platform\": \"3DS\", \"Score\": 92},\n",
    "        {\"Game\": \"Donkey Kong Country Returns\", \"Platform\": \"Wii\", \"Score\": 87},\n",
    "        {\"Game\": \"Luigi's Mansion 3\", \"Platform\": \"Switch\", \"Score\": 86},\n",
    "        {\"Game\": \"Pikmin 3\", \"Platform\": \"Wii U\", \"Score\": 85},\n",
    "        {\"Game\": \"Animal Crossing: New Leaf\", \"Platform\": \"3DS\", \"Score\": 88}\n",
    "    ]\n",
    "    # Sort the games list by Score\n",
    "    # If top is True, descending order\n",
    "    sorted_games = sorted(data, key=lambda x: x['Score'], reverse=top)\n",
    "    \n",
    "    # Return the N games\n",
    "    return sorted_games[:num_games]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15908ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent with the multiple tools\n",
    "data_analyst_agent = Agent(\n",
    "    role=\"Game Stats Assistant\",\n",
    "    instructions=\"You can bring insights about a game dataset based on users questions\",\n",
    "    tools=[get_games]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b982bbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"You're an AI Agent and your role is Game Stats Assistant. Your instructions: You can bring insights about a game dataset based on users questions\" role='system'\n",
      "content=\"What's the best game in the dataset?\" role='user'\n",
      "content=None role='assistant' tool_calls=[ChatCompletionMessageToolCall(id='call_lCcYDtEfEHiNd6jSGcv3HlvC', function=Function(arguments='{\"num_games\":1,\"top\":true}', name='get_games'), type='function')]\n",
      "content='[{\"Game\": \"The Legend of Zelda: Breath of the Wild\", \"Platform\": \"Switch\", \"Score\": 98}]' role='tool' tool_call_id='call_lCcYDtEfEHiNd6jSGcv3HlvC' name='get_games'\n",
      "content='The best game in the dataset is \"The Legend of Zelda: Breath of the Wild\" for the Switch, with a score of 98.' role='assistant' tool_calls=None\n",
      "The best game in the dataset is \"The Legend of Zelda: Breath of the Wild\" for the Switch, with a score of 98.\n"
     ]
    }
   ],
   "source": [
    "response = data_analyst_agent.invoke(\"What's the best game in the dataset?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab4f1b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"You're an AI Agent and your role is Game Stats Assistant. Your instructions: You can bring insights about a game dataset based on users questions\" role='system'\n",
      "content=\"What's the worst game in the dataset?\" role='user'\n",
      "content=None role='assistant' tool_calls=[ChatCompletionMessageToolCall(id='call_2gOlDuDgH8YYAB0bRvV4YY5d', function=Function(arguments='{\"num_games\":1,\"top\":false}', name='get_games'), type='function')]\n",
      "content='[{\"Game\": \"Pikmin 3\", \"Platform\": \"Wii U\", \"Score\": 85}]' role='tool' tool_call_id='call_2gOlDuDgH8YYAB0bRvV4YY5d' name='get_games'\n",
      "content='The worst game in the dataset is \"Pikmin 3\" for the Wii U, with a score of 85.' role='assistant' tool_calls=None\n",
      "The worst game in the dataset is \"Pikmin 3\" for the Wii U, with a score of 85.\n"
     ]
    }
   ],
   "source": [
    "response = data_analyst_agent.invoke(\"What's the worst game in the dataset?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf88891d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
